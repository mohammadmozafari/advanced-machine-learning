{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oma2ZStyqpQe"
      },
      "source": [
        "# CE-40959: Advanced Machine Learning\n",
        "## HW1 - Black-box Meta Learning (100 points)\n",
        "\n",
        "#### Name: Mohammad Mozafari\n",
        "#### Student No: 400201167"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zATL8bguriGR"
      },
      "source": [
        "In this notebook, you are going to implement a black-box meta learner using the `Omniglot` dataset.\n",
        "\n",
        "Please write your code in specified sections and do not change anything else. If you have a question regarding this homework, please ask it on the Quera.\n",
        "\n",
        "Also, it is recommended to use Google Colab to do this homework. You can connect to your drive using the code below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSsY1Jw7pwZc"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZJ_Hv8Uqoil"
      },
      "source": [
        "## Import Required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2NGBSeo0L6Vu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "import random\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xabeci_XPcU2"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNHVKqRMM2oD"
      },
      "source": [
        "In Meta-Learning literature and in the meta-training phase, you are given some batches which consist of `support` and `query` sets. you train your model in a way that by using a support set you could predict query set labels correctly.\n",
        "\n",
        "In this homework, you are going to implement such meta-learner like the below architecture. In this model, at each step, you give all your support images and one query to the network simultaneously (query at the end) and you expect that the model predicts query label based on your inputs.\n",
        "\n",
        "\n",
        "<br><br>\n",
        "\n",
        "<div style=\"text-align:center;\"><img src=\"https://drive.google.com/uc?export=view&id=1Au9GF7FB_IChrMLmvM0z4RBPP1R3oPgY\" width=300></div>\n",
        "\n",
        "<br><br>\n",
        "\n",
        "Don't worry if you didn't understand the architecture. we are going to explain it step by step.\n",
        "\n",
        "So if our meta-learning is K-shot N-way then each batch will consist of N*K support images with labels and one query image which we have its label in the meta-training phase.\n",
        "\n",
        "First we should build dataset it this way that each batch return N*K+1 images\n",
        "\n",
        "The Omniglot data set is designed for developing more human-like learning algorithms. It contains 1623 different handwritten characters from 50 different alphabets. Each of the 1623 characters was drawn online via Amazon's Mechanical Turk by 20 different people.\n",
        "\n",
        "Train and test dataset contains 964 and 659 classes, respectively. Torchvision-based Omniglot dataset is ordered and every 20 images in a row belong to one class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZU6nY6ZPDJla"
      },
      "outputs": [],
      "source": [
        "# Meta learning parameters.\n",
        "\n",
        "N = 5\n",
        "K = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8bS05XnPe7v"
      },
      "source": [
        "## Prepare dataset (25 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286,
          "referenced_widgets": [
            "6e583c8c0d69404c94b4dd7d1001cd0d",
            "f3b5974dd01046e5a05a230461253603",
            "3f687b3217bf4ceab381f42f9968070c",
            "6a96fb8af3e843b795c8648a309908f9",
            "869e57d57b6f493bad1c35fe37283f96",
            "9432063caf754ee983c7bf83994dc0a5",
            "abd038de23244dc09cae723aba2b7fdc",
            "a6a7b25369c54604a9ac73c64c30d61c",
            "288f0e1111e04ccc9b66810573a962be",
            "c2d9652aeb5742dfa16263fcb6c35f10",
            "8e1702f51f66414da07e65a68ae789bd",
            "d841c4f6452f47d88278dda60373e7c1",
            "d11f8d483e1a49eaa00a77aad39c7e82",
            "b5af0d1ba5ee4df283e9d2a2ccef231a",
            "356078d55f144906994a2995a2ba6285",
            "4011f4a5053e4ce48fd246d922682c29",
            "ea80671540b04065aa7a145f4d142a60",
            "6a30fafc3eba4dde957d9a04a0d4b00d",
            "8d528135c7984b5b81ee8d2bddabf0b1",
            "324c3b6b2a7f49f0817f2ad70cae161f",
            "3f78c864ae994416acb6fa98fc1ac7bd",
            "1edf6cbeae2b46fdafd7a615ef62c1d1"
          ]
        },
        "id": "pMXx6_Py9AhO",
        "outputId": "b636b03d-e56d-4bdf-894e-8a6f645acecc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://raw.githubusercontent.com/brendenlake/omniglot/master/python/images_background.zip to ./data/omniglot/omniglot-py/images_background.zip\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6e583c8c0d69404c94b4dd7d1001cd0d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/9464212 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/omniglot/omniglot-py/images_background.zip to ./data/omniglot/omniglot-py\n",
            "Downloading https://raw.githubusercontent.com/brendenlake/omniglot/master/python/images_evaluation.zip to ./data/omniglot/omniglot-py/images_evaluation.zip\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d841c4f6452f47d88278dda60373e7c1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/6462886 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/omniglot/omniglot-py/images_evaluation.zip to ./data/omniglot/omniglot-py\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize(28),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.Omniglot('./data/omniglot/', download = True, background = True, transform = transform)\n",
        "test_dataset = torchvision.datasets.Omniglot('./data/omniglot/', download = True, background = False, transform = transform)\n",
        "\n",
        "train_labels = np.repeat(np.arange(964), 20)\n",
        "test_labels = np.repeat(np.arange(659), 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWK0vksv4nVh"
      },
      "source": [
        "To build a dataloader, we should have a class that yields indexes of selected data in the dataset for every iteration and pass it to the `batch_sampler` attribute of dataloader.\n",
        "\n",
        "Complete below code based on this pseudocode:\n",
        "\n",
        "\n",
        "1.   select `N` classes randomly from all classes\n",
        "2.   select `1` class from `N` selected classes as query-contained class\n",
        "3.   select `K` images from other `N-1` classes independently and randomly\n",
        "4.   select `K+1` images from the query-contained class independently and randomly\n",
        "5.   shuffle dataset indexes, but don't forget to put query index at the last of the list\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yODgabjHEY9A"
      },
      "outputs": [],
      "source": [
        "class BatchSampler(object):\n",
        "    \"\"\"\n",
        "    BatchSampler: yield a batch of indexes at each iteration.\n",
        "    __len__ returns the number of episodes per epoch (same as 'self.iterations').\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, labels, classes_per_it, num_samples, iterations, batch_size):\n",
        "        \"\"\"\n",
        "        Initialize the BatchSampler object\n",
        "        Arguments:\n",
        "        - labels: array of labels of dataset.\n",
        "        - classes_per_it: number of random classes for each iteration\n",
        "        - num_samples: number of samples for each iteration for each class\n",
        "        - iterations: number of iterations (episodes) per epoch\n",
        "        - batch_size: number of batches per iteration\n",
        "        \"\"\"\n",
        "        super(BatchSampler, self).__init__()\n",
        "        self.labels = labels\n",
        "        self.classes_per_it = classes_per_it\n",
        "        self.sample_per_class = num_samples\n",
        "        self.iterations = iterations\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def __iter__(self):\n",
        "        '''\n",
        "        yield a batch of indexes\n",
        "        '''\n",
        "\n",
        "        for it in range(self.iterations):\n",
        "            total_batch_indexes = np.array([])\n",
        "\n",
        "            #################################################################################\n",
        "            #                  COMPLETE THE FOLLOWING SECTION (25 points)                   #\n",
        "            #################################################################################\n",
        "            # feel free to add/edit initialization part of sampler.\n",
        "            #################################################################################\n",
        "\n",
        "            unique_labels = np.unique(self.labels)\n",
        "            for _ in range(self.batch_size):\n",
        "                random_classes = np.random.choice(unique_labels, size=self.classes_per_it, replace=False)\n",
        "                seq = np.zeros(self.classes_per_it * self.sample_per_class + 1)\n",
        "                for i, c in enumerate(random_classes):\n",
        "                    count = self.sample_per_class\n",
        "                    if i == len(random_classes) - 1:\n",
        "                        count += 1\n",
        "                    random_indices = np.random.randint(20*c, 20*c+20, size=count)\n",
        "                    seq[i*self.sample_per_class:i*self.sample_per_class+count] = random_indices\n",
        "                np.random.shuffle(seq[:-1])\n",
        "                total_batch_indexes = np.concatenate((total_batch_indexes, seq))\n",
        "\n",
        "            #################################################################################\n",
        "            #                                   THE END                                     #\n",
        "            #################################################################################\n",
        "\n",
        "            yield total_batch_indexes.astype(int)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.iterations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vkaRutIUPF4b"
      },
      "outputs": [],
      "source": [
        "iterations = 5000\n",
        "batch_size = 32\n",
        "\n",
        "train_sampler = BatchSampler(labels=train_labels, classes_per_it=N,\n",
        "                              num_samples=K, iterations=iterations,\n",
        "                              batch_size=batch_size)\n",
        "\n",
        "test_sampler = BatchSampler(labels=test_labels, classes_per_it=N,\n",
        "                              num_samples=K, iterations=iterations,\n",
        "                              batch_size=batch_size)\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_sampler=train_sampler)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_sampler=test_sampler)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnvAPmPmPh92"
      },
      "source": [
        "## Model (50 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52JCi9o-M2sp"
      },
      "source": [
        "Let's Build our model. the first block of our model is one encoder which is given below. you are going to implement other blocks of networks with a given explanation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "eY3brHqVVXdb"
      },
      "outputs": [],
      "source": [
        "def conv_block(in_channels, out_channels):\n",
        "    return nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels, momentum=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "class OmniglotNet(nn.Module):\n",
        "    '''\n",
        "    source: https://github.com/jakesnell/prototypical-networks/blob/f0c48808e496989d01db59f86d4449d7aee9ab0c/protonets/models/few_shot.py#L62-L84\n",
        "    '''\n",
        "    def __init__(self, x_dim=1, hid_dim=64, z_dim=64):\n",
        "        super(OmniglotNet, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            conv_block(x_dim, hid_dim),\n",
        "            conv_block(hid_dim, hid_dim),\n",
        "            conv_block(hid_dim, hid_dim),\n",
        "            conv_block(hid_dim, z_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        return x.view(x.size(0), -1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vr11qLidnqqW"
      },
      "source": [
        "The whole network consists of two major blocks:\n",
        "\n",
        "\n",
        "1.   Causal Attention\n",
        "2.   Temporal Convolution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlOp-rImjs9d"
      },
      "source": [
        "The first block is `Causal Attention`:\n",
        "\n",
        "\n",
        "<div style=\"text-align:center;\"><img src=\"https://drive.google.com/uc?export=view&id=19lWuKzYTRry-UBog838o7dWYVL-r54WF\" width=500></div>\n",
        "\n",
        "<br><br>\n",
        "\n",
        "The mechanism is so similar to self-attention (if you don't have any information about self-attention, see [this link](https://www.geeksforgeeks.org/self-attention-in-nlp/)) with one difference. the `masked softmax` has been replaced by `softmax`. It means that at each timestep when you calculate weights of the attention mechanism, you do it with just past keys/values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QK-n-CvSjtBV"
      },
      "outputs": [],
      "source": [
        "class AttentionBlock(nn.Module):\n",
        "    def __init__(self, in_channels, key_size, value_size):\n",
        "        super(AttentionBlock, self).__init__()\n",
        "\n",
        "        #################################################################################\n",
        "        #                  COMPLETE THE FOLLOWING SECTION (2.5 points)                  #\n",
        "        #################################################################################\n",
        "        self.key_affine = nn.Linear(in_channels, key_size)\n",
        "        self.query_affine = nn.Linear(in_channels, key_size)\n",
        "        self.value_affine = nn.Linear(in_channels, value_size)\n",
        "        #################################################################################\n",
        "        #                                   THE END                                     #\n",
        "        #################################################################################\n",
        "        self.softmax_temp = math.sqrt(key_size) #don't forget to apply temperature before calculating softmax.\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x is dim (N, T, in_channels) where N is the batch_size, and T is the sequence length\n",
        "        mask = np.array([[1 if i>j else 0 for i in range(x.shape[1])] for j in range(x.shape[1])])\n",
        "        mask = torch.ByteTensor(mask).to(x.device)\n",
        "\n",
        "      \n",
        "        #################################################################################\n",
        "        #                  COMPLETE THE FOLLOWING SECTION (7.5 points)                  #\n",
        "        #################################################################################\n",
        "        keys = self.key_affine(x)                                    # keys:    (N, T, K)\n",
        "        queries = self.query_affine(x)                               # queries: (N, T, K)\n",
        "        values = self.value_affine(x)                                # values:  (N, T, V)\n",
        "\n",
        "        logits = torch.bmm(queries, keys.permute((0, 2, 1)))         # logits:  (N, T, T)\n",
        "        logits.data.masked_fill_(mask, -float('inf'))\n",
        "        weights = F.softmax(logits/self.softmax_temp, dim=2)\n",
        "        output = torch.bmm(weights, values)                          # output:  (N, T, V)             \n",
        "\n",
        "        return torch.cat((x, output), dim=2)\n",
        "        #################################################################################\n",
        "        #                                   THE END                                     #\n",
        "        #################################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8V3lTcd30tW"
      },
      "source": [
        "The second block is `Temporal Convolution`:\n",
        "\n",
        "a Temporal Convolution consists of a series of `Dense Blocks` whose dilation rates increase exponentially until their receptive field exceeds the desired sequence length. For example first time when you apply this block, sequence length is (N*K+1) and dilation is 2.\n",
        "to sum up, what you will do is this:\n",
        "\n",
        "<div style=\"text-align:center;\"><img src=\"https://drive.google.com/uc?export=view&id=1_mWTFiZNQlN4sMTWp2GqolSSzNTAFJuh\" width=1000></div>\n",
        "\n",
        "<br>\n",
        "Dense Block pseduocode is:\n",
        "<br><br>\n",
        "\n",
        "<div style=\"text-align:center;\"><img src=\"https://drive.google.com/uc?export=view&id=1T2q6KugqBEcwSyJAAGymTaXTe__MGsv3\" width=1000></div>\n",
        "\n",
        "<br>\n",
        "The `CausalConv` code is given.\n",
        "\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "G2wn9BPeUHPY"
      },
      "outputs": [],
      "source": [
        "class CasualConv1d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, dilation=1):\n",
        "        super(CasualConv1d, self).__init__()\n",
        "\n",
        "        self.pad = nn.ConstantPad1d((dilation, 0), 0)\n",
        "        self.conv1d = nn.Conv1d(in_channels, out_channels, kernel_size=2, dilation=dilation)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv1d(self.pad(x))\n",
        "\n",
        "class DenseBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, dilation):\n",
        "        super().__init__()\n",
        "\n",
        "        #################################################################################\n",
        "        #                  COMPLETE THE FOLLOWING SECTION (2.5 points)                  #\n",
        "        #################################################################################\n",
        "        self.cc1 = CasualConv1d(in_channels, out_channels, dilation)\n",
        "        self.cc2 = CasualConv1d(in_channels, out_channels, dilation)\n",
        "        #################################################################################\n",
        "        #                                   THE END                                     #\n",
        "        #################################################################################\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        #################################################################################\n",
        "        #                  COMPLETE THE FOLLOWING SECTION (5 points)                    #\n",
        "        #################################################################################\n",
        "        xf = self.cc1(x)\n",
        "        xg = self.cc2(x)\n",
        "        activation = torch.tanh(xf) * torch.sigmoid(xg)\n",
        "        return torch.cat((x, activation), dim=1)\n",
        "        #################################################################################\n",
        "        #                                   THE END                                     #\n",
        "        #################################################################################\n",
        "\n",
        "\n",
        "\n",
        "class TemporalConvolutionBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, sequence_length, in_channels, dense_block_out_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        #################################################################################\n",
        "        #                  COMPLETE THE FOLLOWING SECTION (2.5 points)                  #\n",
        "        #################################################################################\n",
        "        dblocks = []\n",
        "        for i in range(np.math.ceil(np.math.log2(sequence_length))):\n",
        "            db = DenseBlock(in_channels + i * dense_block_out_channels, dense_block_out_channels, 2 ** (i+1))\n",
        "            dblocks.append(db)\n",
        "        self.dense_blocks = nn.ModuleList(dblocks)\n",
        "        #################################################################################\n",
        "        #                                   THE END                                     #\n",
        "        #################################################################################\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        #################################################################################\n",
        "        #                  COMPLETE THE FOLLOWING SECTION (10 points)                   #\n",
        "        #################################################################################\n",
        "        x = x.permute(0, 2, 1)\n",
        "        for db in self.dense_blocks: \n",
        "            x = db(x)\n",
        "        return x.permute(0, 2, 1)\n",
        "        #################################################################################\n",
        "        #                                   THE END                                     #\n",
        "        #################################################################################\n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "nZjfogMlnApy"
      },
      "outputs": [],
      "source": [
        "# The general mechanism of the network is as follows:\n",
        "# Your input shape is (B*S, C, H, W). B is batch size, S is sequence length, C is channel, H is height and W is width of your image.\n",
        "# first you should pass your input to \"OmniglotNet\" network to get feature vectors per data. shape: (B*S, V). V is feature vector size.\n",
        "# then separate B and S dimensions and concat one-hot labels with your data. Shape: (B, S, V + N). N is your meta-learner parameter (number of classes per batch)\n",
        "# pass it to a attention block with key size of 64 and value size of 32. shape: (B, S, v1)\n",
        "# pass it to a temporal convolution block which consists of dense blocks with 128 output channels. shape: (B, S, v2)\n",
        "# pass it to a attention block with key size of 256 and value size of 128. shape: (B, S, v3)\n",
        "# pass it to a temporal convolution block which consists of dense blocks with 128 output channels. shape: (B, S, v4)\n",
        "# pass it to a attention block with key size of 512 and value size of 256. shape: (B, S, v5)\n",
        "# pass it to a Linear block with N outputs to predict labels. shape: (B, S, N)\n",
        "# return last index of sequence which is related to query (second dimension). shape: (B, N)\n",
        "\n",
        "class Network(nn.Module):\n",
        "    def __init__(self, N, K):\n",
        "        super(Network, self).__init__()\n",
        "\n",
        "        self.N = N\n",
        "        self.K = K\n",
        "        self.encoder = OmniglotNet()\n",
        "        channels_number = 64 + N\n",
        "        tc_layers = np.math.ceil(np.math.log2(N*K+1))\n",
        "\n",
        "        #################################################################################\n",
        "        #                  COMPLETE THE FOLLOWING SECTION (10 points)                   #\n",
        "        #################################################################################\n",
        "        self.attn1 = AttentionBlock(channels_number, 64, 32)\n",
        "        channels_number += 32\n",
        "        self.tc1 = TemporalConvolutionBlock(N*K+1, channels_number, 128)\n",
        "        channels_number += 128 * tc_layers\n",
        "        \n",
        "        self.attn2 = AttentionBlock(channels_number, 256, 128)\n",
        "        channels_number += 128\n",
        "        self.tc2 = TemporalConvolutionBlock(N*K+1, channels_number, 128)\n",
        "        channels_number += 128 * tc_layers\n",
        "        \n",
        "        self.attn3 = AttentionBlock(channels_number, 512, 256)\n",
        "        channels_number += 256\n",
        "        \n",
        "        self.linear = nn.Linear(channels_number, N)\n",
        "        #################################################################################\n",
        "        #                                   THE END                                     #\n",
        "        #################################################################################\n",
        "\n",
        "\n",
        "    def forward(self, input, labels):\n",
        "\n",
        "        #################################################################################\n",
        "        #                  COMPLETE THE FOLLOWING SECTION (10 points)                   #\n",
        "        #################################################################################\n",
        "        # input shape is (B*S, C, H, W)\n",
        "        # labels shape is (B, S, N)\n",
        "        # output shape is (N, N)\n",
        "        # calculate output by given description\n",
        "        #################################################################################\n",
        "        B, S = labels.shape[:2]\n",
        "\n",
        "        x = self.encoder(input)                       # x: (B*S, V)\n",
        "        x = x.view(B, S, -1)                          # x: (B, S, V)\n",
        "        x = torch.cat((x, labels), dim=2)             # x: (B, S, V+N)\n",
        "        x = x.type(torch.float32)\n",
        "\n",
        "        x = self.attn1(x)\n",
        "        x = self.tc1(x)\n",
        "        x = self.attn2(x)\n",
        "        x = self.tc2(x)\n",
        "        x = self.attn3(x)\n",
        "        x = self.linear(x)\n",
        "\n",
        "        return x[:, -1, :]\n",
        "        #################################################################################\n",
        "        #                                   THE END                                     #\n",
        "        #################################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "si_-sVXgbYbr"
      },
      "source": [
        "## Train (15 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "2lKeMs08kFgS"
      },
      "outputs": [],
      "source": [
        "def labels_to_one_hot(labels):\n",
        "    unique = np.unique(labels)\n",
        "    map = {label:idx for idx, label in enumerate(unique)}\n",
        "    idxs = [map[labels[i]] for i in range(labels.size)]\n",
        "    one_hot = np.zeros((labels.size, unique.size))\n",
        "    one_hot[np.arange(labels.size), idxs] = 1\n",
        "    return one_hot, idxs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwyVINHPbc5q",
        "outputId": "8138cc32-ed02-4c85-c251-33f02b67bd91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0/4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/cuda/Indexing.cu:963.)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1,    50] loss: 1.624 accuracy: 0.226\n",
            "[1,   100] loss: 1.599 accuracy: 0.234\n",
            "[1,   150] loss: 1.559 accuracy: 0.286\n",
            "[1,   200] loss: 1.532 accuracy: 0.303\n",
            "[1,   250] loss: 1.545 accuracy: 0.289\n",
            "[1,   300] loss: 1.502 accuracy: 0.337\n",
            "[1,   350] loss: 1.512 accuracy: 0.308\n",
            "[1,   400] loss: 1.443 accuracy: 0.346\n",
            "[1,   450] loss: 1.387 accuracy: 0.368\n",
            "[1,   500] loss: 1.352 accuracy: 0.403\n",
            "[1,   550] loss: 1.242 accuracy: 0.472\n",
            "[1,   600] loss: 1.157 accuracy: 0.499\n",
            "[1,   650] loss: 1.029 accuracy: 0.569\n",
            "[1,   700] loss: 0.938 accuracy: 0.602\n",
            "[1,   750] loss: 0.842 accuracy: 0.651\n",
            "[1,   800] loss: 0.786 accuracy: 0.667\n",
            "[1,   850] loss: 0.732 accuracy: 0.697\n",
            "[1,   900] loss: 0.653 accuracy: 0.732\n",
            "[1,   950] loss: 0.599 accuracy: 0.761\n",
            "[1,  1000] loss: 0.535 accuracy: 0.787\n",
            "[1,  1050] loss: 0.471 accuracy: 0.811\n",
            "[1,  1100] loss: 0.431 accuracy: 0.835\n",
            "[1,  1150] loss: 0.432 accuracy: 0.822\n",
            "[1,  1200] loss: 0.409 accuracy: 0.836\n",
            "[1,  1250] loss: 0.411 accuracy: 0.844\n",
            "[1,  1300] loss: 0.375 accuracy: 0.856\n",
            "[1,  1350] loss: 0.340 accuracy: 0.873\n",
            "[1,  1400] loss: 0.340 accuracy: 0.869\n",
            "[1,  1450] loss: 0.332 accuracy: 0.869\n",
            "[1,  1500] loss: 0.322 accuracy: 0.881\n",
            "[1,  1550] loss: 0.299 accuracy: 0.886\n",
            "[1,  1600] loss: 0.279 accuracy: 0.896\n",
            "[1,  1650] loss: 0.312 accuracy: 0.888\n",
            "[1,  1700] loss: 0.297 accuracy: 0.882\n",
            "[1,  1750] loss: 0.263 accuracy: 0.911\n",
            "[1,  1800] loss: 0.276 accuracy: 0.897\n",
            "[1,  1850] loss: 0.273 accuracy: 0.901\n",
            "[1,  1900] loss: 0.283 accuracy: 0.896\n",
            "[1,  1950] loss: 0.255 accuracy: 0.919\n",
            "[1,  2000] loss: 0.217 accuracy: 0.923\n",
            "[1,  2050] loss: 0.233 accuracy: 0.911\n",
            "[1,  2100] loss: 0.249 accuracy: 0.906\n",
            "[1,  2150] loss: 0.193 accuracy: 0.943\n",
            "[1,  2200] loss: 0.207 accuracy: 0.921\n",
            "[1,  2250] loss: 0.231 accuracy: 0.912\n",
            "[1,  2300] loss: 0.229 accuracy: 0.920\n",
            "[1,  2350] loss: 0.226 accuracy: 0.916\n",
            "[1,  2400] loss: 0.205 accuracy: 0.934\n",
            "[1,  2450] loss: 0.220 accuracy: 0.922\n",
            "[1,  2500] loss: 0.197 accuracy: 0.926\n",
            "[1,  2550] loss: 0.205 accuracy: 0.916\n",
            "[1,  2600] loss: 0.177 accuracy: 0.934\n",
            "[1,  2650] loss: 0.175 accuracy: 0.936\n",
            "[1,  2700] loss: 0.185 accuracy: 0.933\n",
            "[1,  2750] loss: 0.152 accuracy: 0.948\n",
            "[1,  2800] loss: 0.167 accuracy: 0.934\n",
            "[1,  2850] loss: 0.213 accuracy: 0.929\n",
            "[1,  2900] loss: 0.185 accuracy: 0.936\n",
            "[1,  2950] loss: 0.173 accuracy: 0.933\n",
            "[1,  3000] loss: 0.190 accuracy: 0.936\n",
            "[1,  3050] loss: 0.150 accuracy: 0.943\n",
            "[1,  3100] loss: 0.141 accuracy: 0.952\n",
            "[1,  3150] loss: 0.170 accuracy: 0.942\n",
            "[1,  3200] loss: 0.161 accuracy: 0.938\n",
            "[1,  3250] loss: 0.166 accuracy: 0.941\n",
            "[1,  3300] loss: 0.138 accuracy: 0.946\n",
            "[1,  3350] loss: 0.144 accuracy: 0.952\n",
            "[1,  3400] loss: 0.156 accuracy: 0.947\n",
            "[1,  3450] loss: 0.168 accuracy: 0.935\n",
            "[1,  3500] loss: 0.133 accuracy: 0.950\n",
            "[1,  3550] loss: 0.165 accuracy: 0.942\n",
            "[1,  3600] loss: 0.193 accuracy: 0.934\n",
            "[1,  3650] loss: 0.155 accuracy: 0.946\n",
            "[1,  3700] loss: 0.165 accuracy: 0.938\n",
            "[1,  3750] loss: 0.140 accuracy: 0.949\n",
            "[1,  3800] loss: 0.157 accuracy: 0.945\n",
            "[1,  3850] loss: 0.163 accuracy: 0.936\n",
            "[1,  3900] loss: 0.126 accuracy: 0.956\n",
            "[1,  3950] loss: 0.158 accuracy: 0.947\n",
            "[1,  4000] loss: 0.136 accuracy: 0.951\n",
            "[1,  4050] loss: 0.109 accuracy: 0.957\n",
            "[1,  4100] loss: 0.127 accuracy: 0.954\n",
            "[1,  4150] loss: 0.161 accuracy: 0.943\n",
            "[1,  4200] loss: 0.139 accuracy: 0.945\n",
            "[1,  4250] loss: 0.124 accuracy: 0.953\n",
            "[1,  4300] loss: 0.164 accuracy: 0.944\n",
            "[1,  4350] loss: 0.132 accuracy: 0.952\n",
            "[1,  4400] loss: 0.179 accuracy: 0.933\n",
            "[1,  4450] loss: 0.126 accuracy: 0.949\n",
            "[1,  4500] loss: 0.121 accuracy: 0.952\n",
            "[1,  4550] loss: 0.126 accuracy: 0.956\n",
            "[1,  4600] loss: 0.117 accuracy: 0.958\n",
            "[1,  4650] loss: 0.111 accuracy: 0.959\n",
            "[1,  4700] loss: 0.121 accuracy: 0.957\n",
            "[1,  4750] loss: 0.122 accuracy: 0.948\n",
            "[1,  4800] loss: 0.127 accuracy: 0.954\n",
            "[1,  4850] loss: 0.127 accuracy: 0.951\n",
            "[1,  4900] loss: 0.108 accuracy: 0.956\n",
            "[1,  4950] loss: 0.099 accuracy: 0.963\n",
            "[1,  5000] loss: 0.124 accuracy: 0.954\n",
            "Epoch 1/4\n",
            "[2,    50] loss: 0.127 accuracy: 0.954\n",
            "[2,   100] loss: 0.124 accuracy: 0.952\n",
            "[2,   150] loss: 0.154 accuracy: 0.939\n",
            "[2,   200] loss: 0.129 accuracy: 0.953\n",
            "[2,   250] loss: 0.099 accuracy: 0.966\n",
            "[2,   300] loss: 0.106 accuracy: 0.962\n",
            "[2,   350] loss: 0.110 accuracy: 0.959\n",
            "[2,   400] loss: 0.110 accuracy: 0.962\n",
            "[2,   450] loss: 0.111 accuracy: 0.958\n",
            "[2,   500] loss: 0.109 accuracy: 0.958\n",
            "[2,   550] loss: 0.139 accuracy: 0.952\n",
            "[2,   600] loss: 0.111 accuracy: 0.957\n",
            "[2,   650] loss: 0.104 accuracy: 0.961\n",
            "[2,   700] loss: 0.095 accuracy: 0.971\n",
            "[2,   750] loss: 0.125 accuracy: 0.952\n",
            "[2,   800] loss: 0.116 accuracy: 0.956\n",
            "[2,   850] loss: 0.119 accuracy: 0.954\n",
            "[2,   900] loss: 0.110 accuracy: 0.955\n",
            "[2,   950] loss: 0.111 accuracy: 0.953\n",
            "[2,  1000] loss: 0.113 accuracy: 0.956\n",
            "[2,  1050] loss: 0.087 accuracy: 0.963\n",
            "[2,  1100] loss: 0.113 accuracy: 0.959\n",
            "[2,  1150] loss: 0.105 accuracy: 0.957\n",
            "[2,  1200] loss: 0.122 accuracy: 0.959\n",
            "[2,  1250] loss: 0.092 accuracy: 0.971\n",
            "[2,  1300] loss: 0.099 accuracy: 0.964\n",
            "[2,  1350] loss: 0.089 accuracy: 0.969\n",
            "[2,  1400] loss: 0.116 accuracy: 0.960\n",
            "[2,  1450] loss: 0.104 accuracy: 0.965\n",
            "[2,  1500] loss: 0.116 accuracy: 0.956\n",
            "[2,  1550] loss: 0.096 accuracy: 0.965\n",
            "[2,  1600] loss: 0.101 accuracy: 0.966\n",
            "[2,  1650] loss: 0.100 accuracy: 0.965\n",
            "[2,  1700] loss: 0.086 accuracy: 0.966\n",
            "[2,  1750] loss: 0.135 accuracy: 0.951\n",
            "[2,  1800] loss: 0.089 accuracy: 0.969\n",
            "[2,  1850] loss: 0.093 accuracy: 0.964\n",
            "[2,  1900] loss: 0.095 accuracy: 0.969\n",
            "[2,  1950] loss: 0.113 accuracy: 0.960\n",
            "[2,  2000] loss: 0.113 accuracy: 0.960\n",
            "[2,  2050] loss: 0.117 accuracy: 0.966\n",
            "[2,  2100] loss: 0.092 accuracy: 0.966\n",
            "[2,  2150] loss: 0.111 accuracy: 0.961\n",
            "[2,  2200] loss: 0.089 accuracy: 0.966\n",
            "[2,  2250] loss: 0.081 accuracy: 0.971\n",
            "[2,  2300] loss: 0.078 accuracy: 0.971\n",
            "[2,  2350] loss: 0.096 accuracy: 0.966\n",
            "[2,  2400] loss: 0.075 accuracy: 0.972\n",
            "[2,  2450] loss: 0.117 accuracy: 0.962\n",
            "[2,  2500] loss: 0.100 accuracy: 0.961\n",
            "[2,  2550] loss: 0.075 accuracy: 0.975\n",
            "[2,  2600] loss: 0.083 accuracy: 0.970\n",
            "[2,  2650] loss: 0.095 accuracy: 0.966\n",
            "[2,  2700] loss: 0.097 accuracy: 0.964\n",
            "[2,  2750] loss: 0.093 accuracy: 0.964\n",
            "[2,  2800] loss: 0.093 accuracy: 0.963\n",
            "[2,  2850] loss: 0.089 accuracy: 0.973\n",
            "[2,  2900] loss: 0.087 accuracy: 0.971\n",
            "[2,  2950] loss: 0.077 accuracy: 0.969\n",
            "[2,  3000] loss: 0.069 accuracy: 0.977\n",
            "[2,  3050] loss: 0.098 accuracy: 0.967\n",
            "[2,  3100] loss: 0.080 accuracy: 0.972\n",
            "[2,  3150] loss: 0.111 accuracy: 0.961\n",
            "[2,  3200] loss: 0.103 accuracy: 0.961\n",
            "[2,  3250] loss: 0.124 accuracy: 0.957\n",
            "[2,  3300] loss: 0.079 accuracy: 0.969\n",
            "[2,  3350] loss: 0.077 accuracy: 0.972\n",
            "[2,  3400] loss: 0.092 accuracy: 0.966\n",
            "[2,  3450] loss: 0.072 accuracy: 0.969\n",
            "[2,  3500] loss: 0.084 accuracy: 0.973\n",
            "[2,  3550] loss: 0.096 accuracy: 0.969\n",
            "[2,  3600] loss: 0.092 accuracy: 0.966\n",
            "[2,  3650] loss: 0.080 accuracy: 0.971\n",
            "[2,  3700] loss: 0.090 accuracy: 0.964\n",
            "[2,  3750] loss: 0.078 accuracy: 0.974\n",
            "[2,  3800] loss: 0.079 accuracy: 0.975\n",
            "[2,  3850] loss: 0.087 accuracy: 0.965\n",
            "[2,  3900] loss: 0.090 accuracy: 0.968\n",
            "[2,  3950] loss: 0.065 accuracy: 0.979\n",
            "[2,  4000] loss: 0.098 accuracy: 0.967\n",
            "[2,  4050] loss: 0.068 accuracy: 0.977\n",
            "[2,  4100] loss: 0.064 accuracy: 0.974\n",
            "[2,  4150] loss: 0.070 accuracy: 0.975\n",
            "[2,  4200] loss: 0.072 accuracy: 0.974\n",
            "[2,  4250] loss: 0.081 accuracy: 0.967\n",
            "[2,  4300] loss: 0.068 accuracy: 0.974\n",
            "[2,  4350] loss: 0.087 accuracy: 0.971\n",
            "[2,  4400] loss: 0.076 accuracy: 0.972\n",
            "[2,  4450] loss: 0.072 accuracy: 0.972\n",
            "[2,  4500] loss: 0.091 accuracy: 0.969\n",
            "[2,  4550] loss: 0.072 accuracy: 0.972\n",
            "[2,  4600] loss: 0.094 accuracy: 0.963\n",
            "[2,  4650] loss: 0.066 accuracy: 0.977\n",
            "[2,  4700] loss: 0.068 accuracy: 0.974\n",
            "[2,  4750] loss: 0.075 accuracy: 0.972\n",
            "[2,  4800] loss: 0.063 accuracy: 0.977\n",
            "[2,  4850] loss: 0.071 accuracy: 0.972\n",
            "[2,  4900] loss: 0.088 accuracy: 0.963\n",
            "[2,  4950] loss: 0.076 accuracy: 0.969\n",
            "[2,  5000] loss: 0.091 accuracy: 0.969\n",
            "Epoch 2/4\n",
            "[3,    50] loss: 0.083 accuracy: 0.969\n",
            "[3,   100] loss: 0.096 accuracy: 0.969\n",
            "[3,   150] loss: 0.070 accuracy: 0.976\n",
            "[3,   200] loss: 0.076 accuracy: 0.967\n",
            "[3,   250] loss: 0.068 accuracy: 0.976\n",
            "[3,   300] loss: 0.067 accuracy: 0.973\n",
            "[3,   350] loss: 0.080 accuracy: 0.971\n",
            "[3,   400] loss: 0.077 accuracy: 0.971\n",
            "[3,   450] loss: 0.062 accuracy: 0.977\n",
            "[3,   500] loss: 0.057 accuracy: 0.980\n",
            "[3,   550] loss: 0.054 accuracy: 0.979\n",
            "[3,   600] loss: 0.078 accuracy: 0.974\n",
            "[3,   650] loss: 0.081 accuracy: 0.972\n",
            "[3,   700] loss: 0.072 accuracy: 0.973\n",
            "[3,   750] loss: 0.048 accuracy: 0.984\n",
            "[3,   800] loss: 0.069 accuracy: 0.973\n",
            "[3,   850] loss: 0.046 accuracy: 0.986\n",
            "[3,   900] loss: 0.072 accuracy: 0.975\n",
            "[3,   950] loss: 0.054 accuracy: 0.979\n",
            "[3,  1000] loss: 0.075 accuracy: 0.971\n",
            "[3,  1050] loss: 0.058 accuracy: 0.977\n",
            "[3,  1100] loss: 0.058 accuracy: 0.982\n",
            "[3,  1150] loss: 0.061 accuracy: 0.980\n",
            "[3,  1200] loss: 0.085 accuracy: 0.967\n",
            "[3,  1250] loss: 0.082 accuracy: 0.971\n",
            "[3,  1300] loss: 0.086 accuracy: 0.968\n",
            "[3,  1350] loss: 0.062 accuracy: 0.977\n",
            "[3,  1400] loss: 0.068 accuracy: 0.976\n",
            "[3,  1450] loss: 0.060 accuracy: 0.978\n",
            "[3,  1500] loss: 0.076 accuracy: 0.971\n",
            "[3,  1550] loss: 0.056 accuracy: 0.979\n",
            "[3,  1600] loss: 0.055 accuracy: 0.981\n",
            "[3,  1650] loss: 0.065 accuracy: 0.977\n",
            "[3,  1700] loss: 0.074 accuracy: 0.972\n",
            "[3,  1750] loss: 0.074 accuracy: 0.971\n",
            "[3,  1800] loss: 0.089 accuracy: 0.969\n",
            "[3,  1850] loss: 0.069 accuracy: 0.976\n",
            "[3,  1900] loss: 0.058 accuracy: 0.979\n",
            "[3,  1950] loss: 0.066 accuracy: 0.975\n",
            "[3,  2000] loss: 0.079 accuracy: 0.969\n",
            "[3,  2050] loss: 0.068 accuracy: 0.976\n",
            "[3,  2100] loss: 0.053 accuracy: 0.979\n",
            "[3,  2150] loss: 0.057 accuracy: 0.982\n",
            "[3,  2200] loss: 0.061 accuracy: 0.975\n",
            "[3,  2250] loss: 0.062 accuracy: 0.978\n",
            "[3,  2300] loss: 0.064 accuracy: 0.978\n",
            "[3,  2350] loss: 0.065 accuracy: 0.974\n",
            "[3,  2400] loss: 0.080 accuracy: 0.977\n",
            "[3,  2450] loss: 0.072 accuracy: 0.977\n",
            "[3,  2500] loss: 0.056 accuracy: 0.977\n",
            "[3,  2550] loss: 0.066 accuracy: 0.976\n",
            "[3,  2600] loss: 0.065 accuracy: 0.973\n",
            "[3,  2650] loss: 0.038 accuracy: 0.986\n",
            "[3,  2700] loss: 0.043 accuracy: 0.982\n",
            "[3,  2750] loss: 0.058 accuracy: 0.977\n",
            "[3,  2800] loss: 0.051 accuracy: 0.983\n",
            "[3,  2850] loss: 0.064 accuracy: 0.975\n",
            "[3,  2900] loss: 0.093 accuracy: 0.967\n",
            "[3,  2950] loss: 0.064 accuracy: 0.978\n",
            "[3,  3000] loss: 0.063 accuracy: 0.976\n",
            "[3,  3050] loss: 0.069 accuracy: 0.978\n",
            "[3,  3100] loss: 0.059 accuracy: 0.980\n",
            "[3,  3150] loss: 0.060 accuracy: 0.975\n",
            "[3,  3200] loss: 0.059 accuracy: 0.979\n",
            "[3,  3250] loss: 0.065 accuracy: 0.976\n",
            "[3,  3300] loss: 0.052 accuracy: 0.984\n",
            "[3,  3350] loss: 0.061 accuracy: 0.977\n",
            "[3,  3400] loss: 0.073 accuracy: 0.975\n",
            "[3,  3450] loss: 0.072 accuracy: 0.971\n",
            "[3,  3500] loss: 0.064 accuracy: 0.979\n",
            "[3,  3550] loss: 0.055 accuracy: 0.978\n",
            "[3,  3600] loss: 0.059 accuracy: 0.981\n",
            "[3,  3650] loss: 0.080 accuracy: 0.969\n",
            "[3,  3700] loss: 0.046 accuracy: 0.982\n",
            "[3,  3750] loss: 0.042 accuracy: 0.984\n",
            "[3,  3800] loss: 0.036 accuracy: 0.989\n",
            "[3,  3850] loss: 0.067 accuracy: 0.979\n",
            "[3,  3900] loss: 0.053 accuracy: 0.984\n",
            "[3,  3950] loss: 0.057 accuracy: 0.981\n",
            "[3,  4000] loss: 0.064 accuracy: 0.976\n",
            "[3,  4050] loss: 0.046 accuracy: 0.984\n",
            "[3,  4100] loss: 0.056 accuracy: 0.978\n",
            "[3,  4150] loss: 0.075 accuracy: 0.974\n",
            "[3,  4200] loss: 0.069 accuracy: 0.975\n",
            "[3,  4250] loss: 0.051 accuracy: 0.979\n",
            "[3,  4300] loss: 0.060 accuracy: 0.981\n",
            "[3,  4350] loss: 0.049 accuracy: 0.982\n",
            "[3,  4400] loss: 0.060 accuracy: 0.980\n",
            "[3,  4450] loss: 0.063 accuracy: 0.981\n",
            "[3,  4500] loss: 0.072 accuracy: 0.976\n",
            "[3,  4550] loss: 0.064 accuracy: 0.979\n",
            "[3,  4600] loss: 0.055 accuracy: 0.978\n",
            "[3,  4650] loss: 0.047 accuracy: 0.983\n",
            "[3,  4700] loss: 0.046 accuracy: 0.984\n",
            "[3,  4750] loss: 0.058 accuracy: 0.979\n",
            "[3,  4800] loss: 0.039 accuracy: 0.984\n",
            "[3,  4850] loss: 0.056 accuracy: 0.981\n",
            "[3,  4900] loss: 0.054 accuracy: 0.977\n",
            "[3,  4950] loss: 0.053 accuracy: 0.981\n",
            "[3,  5000] loss: 0.065 accuracy: 0.982\n",
            "Epoch 3/4\n",
            "[4,    50] loss: 0.047 accuracy: 0.984\n",
            "[4,   100] loss: 0.072 accuracy: 0.974\n",
            "[4,   150] loss: 0.064 accuracy: 0.979\n",
            "[4,   200] loss: 0.051 accuracy: 0.982\n",
            "[4,   250] loss: 0.072 accuracy: 0.971\n",
            "[4,   300] loss: 0.061 accuracy: 0.981\n",
            "[4,   350] loss: 0.049 accuracy: 0.980\n",
            "[4,   400] loss: 0.053 accuracy: 0.983\n",
            "[4,   450] loss: 0.063 accuracy: 0.974\n",
            "[4,   500] loss: 0.066 accuracy: 0.973\n",
            "[4,   550] loss: 0.057 accuracy: 0.982\n",
            "[4,   600] loss: 0.053 accuracy: 0.981\n",
            "[4,   650] loss: 0.035 accuracy: 0.987\n",
            "[4,   700] loss: 0.070 accuracy: 0.980\n",
            "[4,   750] loss: 0.060 accuracy: 0.977\n",
            "[4,   800] loss: 0.048 accuracy: 0.981\n",
            "[4,   850] loss: 0.033 accuracy: 0.987\n",
            "[4,   900] loss: 0.057 accuracy: 0.982\n",
            "[4,   950] loss: 0.048 accuracy: 0.981\n",
            "[4,  1000] loss: 0.061 accuracy: 0.977\n",
            "[4,  1050] loss: 0.061 accuracy: 0.976\n",
            "[4,  1100] loss: 0.037 accuracy: 0.987\n",
            "[4,  1150] loss: 0.053 accuracy: 0.980\n",
            "[4,  1200] loss: 0.056 accuracy: 0.982\n",
            "[4,  1250] loss: 0.048 accuracy: 0.981\n",
            "[4,  1300] loss: 0.055 accuracy: 0.983\n",
            "[4,  1350] loss: 0.056 accuracy: 0.979\n",
            "[4,  1400] loss: 0.046 accuracy: 0.981\n",
            "[4,  1450] loss: 0.037 accuracy: 0.987\n",
            "[4,  1500] loss: 0.040 accuracy: 0.987\n",
            "[4,  1550] loss: 0.034 accuracy: 0.987\n",
            "[4,  1600] loss: 0.063 accuracy: 0.976\n",
            "[4,  1650] loss: 0.049 accuracy: 0.987\n",
            "[4,  1700] loss: 0.054 accuracy: 0.981\n",
            "[4,  1750] loss: 0.056 accuracy: 0.981\n",
            "[4,  1800] loss: 0.048 accuracy: 0.983\n",
            "[4,  1850] loss: 0.041 accuracy: 0.981\n",
            "[4,  1900] loss: 0.056 accuracy: 0.981\n",
            "[4,  1950] loss: 0.048 accuracy: 0.983\n",
            "[4,  2000] loss: 0.054 accuracy: 0.979\n",
            "[4,  2050] loss: 0.056 accuracy: 0.981\n",
            "[4,  2100] loss: 0.048 accuracy: 0.981\n",
            "[4,  2150] loss: 0.069 accuracy: 0.976\n",
            "[4,  2200] loss: 0.071 accuracy: 0.974\n",
            "[4,  2250] loss: 0.047 accuracy: 0.981\n",
            "[4,  2300] loss: 0.043 accuracy: 0.987\n",
            "[4,  2350] loss: 0.059 accuracy: 0.977\n",
            "[4,  2400] loss: 0.043 accuracy: 0.984\n",
            "[4,  2450] loss: 0.043 accuracy: 0.985\n",
            "[4,  2500] loss: 0.055 accuracy: 0.983\n",
            "[4,  2550] loss: 0.047 accuracy: 0.984\n",
            "[4,  2600] loss: 0.051 accuracy: 0.981\n",
            "[4,  2650] loss: 0.052 accuracy: 0.980\n",
            "[4,  2700] loss: 0.048 accuracy: 0.981\n",
            "[4,  2750] loss: 0.060 accuracy: 0.982\n",
            "[4,  2800] loss: 0.055 accuracy: 0.981\n",
            "[4,  2850] loss: 0.054 accuracy: 0.979\n",
            "[4,  2900] loss: 0.039 accuracy: 0.986\n",
            "[4,  2950] loss: 0.062 accuracy: 0.979\n",
            "[4,  3000] loss: 0.040 accuracy: 0.983\n",
            "[4,  3050] loss: 0.054 accuracy: 0.983\n",
            "[4,  3100] loss: 0.040 accuracy: 0.982\n",
            "[4,  3150] loss: 0.042 accuracy: 0.984\n",
            "[4,  3200] loss: 0.056 accuracy: 0.982\n",
            "[4,  3250] loss: 0.046 accuracy: 0.987\n",
            "[4,  3300] loss: 0.040 accuracy: 0.985\n",
            "[4,  3350] loss: 0.043 accuracy: 0.982\n",
            "[4,  3400] loss: 0.060 accuracy: 0.985\n",
            "[4,  3450] loss: 0.044 accuracy: 0.984\n",
            "[4,  3500] loss: 0.049 accuracy: 0.983\n",
            "[4,  3550] loss: 0.053 accuracy: 0.983\n",
            "[4,  3600] loss: 0.033 accuracy: 0.986\n",
            "[4,  3650] loss: 0.041 accuracy: 0.987\n",
            "[4,  3700] loss: 0.038 accuracy: 0.984\n",
            "[4,  3750] loss: 0.063 accuracy: 0.978\n",
            "[4,  3800] loss: 0.044 accuracy: 0.986\n",
            "[4,  3850] loss: 0.059 accuracy: 0.979\n",
            "[4,  3900] loss: 0.040 accuracy: 0.987\n",
            "[4,  3950] loss: 0.049 accuracy: 0.982\n",
            "[4,  4000] loss: 0.068 accuracy: 0.979\n",
            "[4,  4050] loss: 0.045 accuracy: 0.985\n",
            "[4,  4100] loss: 0.038 accuracy: 0.986\n",
            "[4,  4150] loss: 0.048 accuracy: 0.984\n",
            "[4,  4200] loss: 0.042 accuracy: 0.981\n",
            "[4,  4250] loss: 0.040 accuracy: 0.986\n",
            "[4,  4300] loss: 0.040 accuracy: 0.986\n",
            "[4,  4350] loss: 0.043 accuracy: 0.982\n",
            "[4,  4400] loss: 0.051 accuracy: 0.982\n",
            "[4,  4450] loss: 0.044 accuracy: 0.982\n",
            "[4,  4500] loss: 0.044 accuracy: 0.987\n",
            "[4,  4550] loss: 0.051 accuracy: 0.981\n",
            "[4,  4600] loss: 0.050 accuracy: 0.981\n",
            "[4,  4650] loss: 0.047 accuracy: 0.985\n",
            "[4,  4700] loss: 0.035 accuracy: 0.987\n",
            "[4,  4750] loss: 0.042 accuracy: 0.987\n",
            "[4,  4800] loss: 0.037 accuracy: 0.984\n",
            "[4,  4850] loss: 0.049 accuracy: 0.982\n",
            "[4,  4900] loss: 0.041 accuracy: 0.983\n",
            "[4,  4950] loss: 0.040 accuracy: 0.987\n",
            "[4,  5000] loss: 0.040 accuracy: 0.986\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "lr = 5e-4\n",
        "model = Network(N, K).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "epochs = 4\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "model.train()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print('Epoch {}/{}'.format(epoch, epochs))\n",
        "    running_loss, running_acc = 0.0, 0.0\n",
        "    loader_iter = iter(train_dataloader)\n",
        "    for i, batch in enumerate(loader_iter):\n",
        "        #################################################################################\n",
        "        #                  COMPLETE THE FOLLOWING SECTION (15 points)                   #\n",
        "        #################################################################################\n",
        "        # prepare your data as input to your model.\n",
        "        # extract query label (last image label in each batch) for loss function.\n",
        "        # convert your labels to one-hot form and don't forget to set all elements of\n",
        "        # one-hotted query label to zero (it's trivial that we shouldn't give\n",
        "        # the output of the network to model as input!).\n",
        "        # train your model.\n",
        "        # save loss of each iteration\n",
        "        #################################################################################\n",
        "        x, y = batch\n",
        "        x = x.to(device)\n",
        "\n",
        "        # one hot encoding of labels      \n",
        "        one_hots = []\n",
        "        y = y.reshape((-1, K * N + 1))\n",
        "        for j in range(y.shape[0]):\n",
        "            vector, _ = labels_to_one_hot(y[j, :].numpy())\n",
        "            one_hots.append(vector)\n",
        "        y = np.stack(one_hots, axis=0)\n",
        "        targets = y[:, -1, :].argmax(axis=1)\n",
        "        y[:, -1, :] = 0\n",
        "        y = torch.from_numpy(y).to(device)\n",
        "        targets = torch.from_numpy(targets).to(device)\n",
        "\n",
        "        output = model(x, y)\n",
        "        loss = criterion(output, targets)\n",
        "        running_loss += loss\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        preds = output.argmax(dim=1)\n",
        "        acc = ((preds == targets) * 1.0).mean()\n",
        "        running_acc += acc\n",
        "\n",
        "        log_every_iter = 50\n",
        "        if i % log_every_iter == log_every_iter - 1:\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / log_every_iter:.3f} accuracy: {running_acc / log_every_iter:.3f}')\n",
        "            running_loss = 0.0\n",
        "            running_acc = 0.0\n",
        "            fr = 0.0\n",
        "\n",
        "        #################################################################################\n",
        "        #                                   THE END                                     #\n",
        "        #################################################################################\n",
        "\n",
        "torch.save({\n",
        "    'model_state_dict': model.state_dict()\n",
        "}, '{}.pth'.format('snail'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSV1d5zFPuH6"
      },
      "source": [
        "## Test (5 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ALu1EEDQ0RQ",
        "outputId": "e3faa263-fae8-40ce-8636-69331c79c6a9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/cuda/Indexing.cu:963.)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1,    50] partition accuracy: 0.939\n",
            "[1,   100] partition accuracy: 0.942\n",
            "[1,   150] partition accuracy: 0.945\n",
            "[1,   200] partition accuracy: 0.946\n",
            "[1,   250] partition accuracy: 0.953\n",
            "[1,   300] partition accuracy: 0.956\n",
            "[1,   350] partition accuracy: 0.949\n",
            "[1,   400] partition accuracy: 0.942\n",
            "[1,   450] partition accuracy: 0.949\n",
            "[1,   500] partition accuracy: 0.937\n",
            "[1,   550] partition accuracy: 0.949\n",
            "[1,   600] partition accuracy: 0.948\n",
            "[1,   650] partition accuracy: 0.944\n",
            "[1,   700] partition accuracy: 0.951\n",
            "[1,   750] partition accuracy: 0.944\n",
            "[1,   800] partition accuracy: 0.949\n",
            "[1,   850] partition accuracy: 0.959\n",
            "[1,   900] partition accuracy: 0.951\n",
            "[1,   950] partition accuracy: 0.948\n",
            "[1,  1000] partition accuracy: 0.933\n",
            "[1,  1050] partition accuracy: 0.940\n",
            "[1,  1100] partition accuracy: 0.943\n",
            "[1,  1150] partition accuracy: 0.933\n",
            "[1,  1200] partition accuracy: 0.953\n",
            "[1,  1250] partition accuracy: 0.946\n",
            "[1,  1300] partition accuracy: 0.943\n",
            "[1,  1350] partition accuracy: 0.951\n",
            "[1,  1400] partition accuracy: 0.945\n",
            "[1,  1450] partition accuracy: 0.949\n",
            "[1,  1500] partition accuracy: 0.945\n",
            "[1,  1550] partition accuracy: 0.942\n",
            "[1,  1600] partition accuracy: 0.956\n",
            "[1,  1650] partition accuracy: 0.952\n",
            "[1,  1700] partition accuracy: 0.941\n",
            "[1,  1750] partition accuracy: 0.959\n",
            "[1,  1800] partition accuracy: 0.938\n",
            "[1,  1850] partition accuracy: 0.944\n",
            "[1,  1900] partition accuracy: 0.942\n",
            "[1,  1950] partition accuracy: 0.949\n",
            "[1,  2000] partition accuracy: 0.952\n",
            "[1,  2050] partition accuracy: 0.944\n",
            "[1,  2100] partition accuracy: 0.951\n",
            "[1,  2150] partition accuracy: 0.943\n",
            "[1,  2200] partition accuracy: 0.944\n",
            "[1,  2250] partition accuracy: 0.953\n",
            "[1,  2300] partition accuracy: 0.943\n",
            "[1,  2350] partition accuracy: 0.951\n",
            "[1,  2400] partition accuracy: 0.947\n",
            "[1,  2450] partition accuracy: 0.949\n",
            "[1,  2500] partition accuracy: 0.944\n",
            "[1,  2550] partition accuracy: 0.945\n",
            "[1,  2600] partition accuracy: 0.962\n",
            "[1,  2650] partition accuracy: 0.954\n",
            "[1,  2700] partition accuracy: 0.948\n",
            "[1,  2750] partition accuracy: 0.942\n",
            "[1,  2800] partition accuracy: 0.941\n",
            "[1,  2850] partition accuracy: 0.945\n",
            "[1,  2900] partition accuracy: 0.947\n",
            "[1,  2950] partition accuracy: 0.933\n",
            "[1,  3000] partition accuracy: 0.941\n",
            "[1,  3050] partition accuracy: 0.946\n",
            "[1,  3100] partition accuracy: 0.951\n",
            "[1,  3150] partition accuracy: 0.946\n",
            "[1,  3200] partition accuracy: 0.948\n",
            "[1,  3250] partition accuracy: 0.939\n",
            "[1,  3300] partition accuracy: 0.946\n",
            "[1,  3350] partition accuracy: 0.939\n",
            "[1,  3400] partition accuracy: 0.946\n",
            "[1,  3450] partition accuracy: 0.947\n",
            "[1,  3500] partition accuracy: 0.953\n",
            "[1,  3550] partition accuracy: 0.951\n",
            "[1,  3600] partition accuracy: 0.953\n",
            "[1,  3650] partition accuracy: 0.948\n",
            "[1,  3700] partition accuracy: 0.934\n",
            "[1,  3750] partition accuracy: 0.941\n",
            "[1,  3800] partition accuracy: 0.954\n",
            "[1,  3850] partition accuracy: 0.937\n",
            "[1,  3900] partition accuracy: 0.938\n",
            "[1,  3950] partition accuracy: 0.947\n",
            "[1,  4000] partition accuracy: 0.936\n",
            "[1,  4050] partition accuracy: 0.945\n",
            "[1,  4100] partition accuracy: 0.951\n",
            "[1,  4150] partition accuracy: 0.952\n",
            "[1,  4200] partition accuracy: 0.944\n",
            "[1,  4250] partition accuracy: 0.942\n",
            "[1,  4300] partition accuracy: 0.939\n",
            "[1,  4350] partition accuracy: 0.942\n",
            "[1,  4400] partition accuracy: 0.951\n",
            "[1,  4450] partition accuracy: 0.938\n",
            "[1,  4500] partition accuracy: 0.950\n",
            "[1,  4550] partition accuracy: 0.942\n",
            "[1,  4600] partition accuracy: 0.937\n",
            "[1,  4650] partition accuracy: 0.942\n",
            "[1,  4700] partition accuracy: 0.935\n",
            "[1,  4750] partition accuracy: 0.951\n",
            "[1,  4800] partition accuracy: 0.941\n",
            "[1,  4850] partition accuracy: 0.947\n",
            "[1,  4900] partition accuracy: 0.949\n",
            "[1,  4950] partition accuracy: 0.949\n",
            "[1,  5000] partition accuracy: 0.944\n",
            "Total accuracy: 0.9457624554634094\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "test_epochs = 1\n",
        "\n",
        "total_correct = 0\n",
        "total_examples = 0\n",
        "for epoch in range(test_epochs):\n",
        "    loader_iter = iter(test_dataloader)\n",
        "    running_acc = 0.0\n",
        "    for i, batch in enumerate(loader_iter):\n",
        "        #################################################################################\n",
        "        #                  COMPLETE THE FOLLOWING SECTION (5 points)                    #\n",
        "        #################################################################################\n",
        "        # report accuracy of your model.\n",
        "        # plot loss values in whole training iterations.\n",
        "        #################################################################################\n",
        "        x, y = batch\n",
        "        x = x.to(device)\n",
        "\n",
        "        # one hot encoding of labels        \n",
        "        one_hots = []\n",
        "        y = y.reshape((-1, K * N + 1))\n",
        "        for j in range(y.shape[0]):\n",
        "            vector, _ = labels_to_one_hot(y[j, :].numpy())\n",
        "            one_hots.append(vector)\n",
        "        y = np.stack(one_hots, axis=0)\n",
        "        targets = y[:, -1, :].argmax(axis=1)\n",
        "        y[:, -1, :] = 0\n",
        "        y = torch.from_numpy(y).to(device)\n",
        "        targets = torch.from_numpy(targets).to(device)\n",
        "\n",
        "        output = model(x, y)\n",
        "        # running_loss += loss\n",
        "        # optimizer.zero_grad()\n",
        "        # loss.backward()\n",
        "        # optimizer.step()\n",
        "\n",
        "        preds = output.argmax(dim=1)\n",
        "        correct = ((preds == targets) * 1.0).sum()\n",
        "        total_correct += correct\n",
        "        total_examples += preds.shape[0]\n",
        "        running_acc += correct / preds.shape[0]\n",
        "\n",
        "        log_every_iter = 50\n",
        "        if i % log_every_iter == log_every_iter - 1:\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] partition accuracy: {running_acc / log_every_iter:.3f}')\n",
        "            running_acc = 0.0\n",
        "        #################################################################################\n",
        "        #                                   THE END                                     #\n",
        "        #################################################################################\n",
        "    \n",
        "print('Total accuracy: {}'.format(total_correct / total_examples))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AfXPU6FQAwX"
      },
      "source": [
        "## Question (5 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Za9ptSATXq2"
      },
      "source": [
        "Question) State one problem of using this network for meta-learning\n",
        "<br><br>\n",
        "\n",
        "Answer:\n",
        "\n",
        "1. Finding good architecture for TCBlocks and DenseBlocks and how to connect them for different problems can be difficult and time-consuming.\n",
        "2. Model complexity increases with sequence length. (Very large sequences can cause problems)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "fZJ_Hv8Uqoil",
        "xabeci_XPcU2",
        "Z8bS05XnPe7v",
        "xnvAPmPmPh92"
      ],
      "name": "Black_Box_Meta_Learning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1edf6cbeae2b46fdafd7a615ef62c1d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "288f0e1111e04ccc9b66810573a962be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "324c3b6b2a7f49f0817f2ad70cae161f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "356078d55f144906994a2995a2ba6285": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f78c864ae994416acb6fa98fc1ac7bd",
            "placeholder": "",
            "style": "IPY_MODEL_1edf6cbeae2b46fdafd7a615ef62c1d1",
            "value": " 6463488/? [00:00&lt;00:00, 14212591.39it/s]"
          }
        },
        "3f687b3217bf4ceab381f42f9968070c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6a7b25369c54604a9ac73c64c30d61c",
            "max": 9464212,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_288f0e1111e04ccc9b66810573a962be",
            "value": 9464212
          }
        },
        "3f78c864ae994416acb6fa98fc1ac7bd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4011f4a5053e4ce48fd246d922682c29": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a30fafc3eba4dde957d9a04a0d4b00d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a96fb8af3e843b795c8648a309908f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2d9652aeb5742dfa16263fcb6c35f10",
            "placeholder": "",
            "style": "IPY_MODEL_8e1702f51f66414da07e65a68ae789bd",
            "value": " 9464832/? [00:00&lt;00:00, 15761562.86it/s]"
          }
        },
        "6e583c8c0d69404c94b4dd7d1001cd0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f3b5974dd01046e5a05a230461253603",
              "IPY_MODEL_3f687b3217bf4ceab381f42f9968070c",
              "IPY_MODEL_6a96fb8af3e843b795c8648a309908f9"
            ],
            "layout": "IPY_MODEL_869e57d57b6f493bad1c35fe37283f96"
          }
        },
        "869e57d57b6f493bad1c35fe37283f96": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d528135c7984b5b81ee8d2bddabf0b1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e1702f51f66414da07e65a68ae789bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9432063caf754ee983c7bf83994dc0a5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6a7b25369c54604a9ac73c64c30d61c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abd038de23244dc09cae723aba2b7fdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b5af0d1ba5ee4df283e9d2a2ccef231a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d528135c7984b5b81ee8d2bddabf0b1",
            "max": 6462886,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_324c3b6b2a7f49f0817f2ad70cae161f",
            "value": 6462886
          }
        },
        "c2d9652aeb5742dfa16263fcb6c35f10": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d11f8d483e1a49eaa00a77aad39c7e82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea80671540b04065aa7a145f4d142a60",
            "placeholder": "",
            "style": "IPY_MODEL_6a30fafc3eba4dde957d9a04a0d4b00d",
            "value": ""
          }
        },
        "d841c4f6452f47d88278dda60373e7c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d11f8d483e1a49eaa00a77aad39c7e82",
              "IPY_MODEL_b5af0d1ba5ee4df283e9d2a2ccef231a",
              "IPY_MODEL_356078d55f144906994a2995a2ba6285"
            ],
            "layout": "IPY_MODEL_4011f4a5053e4ce48fd246d922682c29"
          }
        },
        "ea80671540b04065aa7a145f4d142a60": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3b5974dd01046e5a05a230461253603": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9432063caf754ee983c7bf83994dc0a5",
            "placeholder": "",
            "style": "IPY_MODEL_abd038de23244dc09cae723aba2b7fdc",
            "value": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
